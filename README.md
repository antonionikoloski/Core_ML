# Core ML

Emotion Recognition Using Smart Glasses and Core ML

## Project overview

This repository contains the code and resources related to my Bachelor thesis, focused on implementing real-time emotion recognition using sensor data collected from smart glasses and Apple's Core ML framework.

Project Overview

The goal of this project was to develop a practical machine learning application capable of accurately detecting human emotions by leveraging multimodal sensor data provided by smart glasses. By combining advanced machine learning techniques with wearable technology, this research aimed to contribute to more intuitive and responsive human-computer interactions.

Key Objectives

Collect and preprocess sensor data from smart glasses, including accelerometer, gyroscope, and camera data.

Train a machine learning model using Core ML to classify emotions effectively in real-time.

Validate the effectiveness and accuracy of the developed emotion recognition model through user trials and evaluation metrics.

Technologies Used

Smart Glasses: Utilized as a wearable data acquisition device.

Core ML: Employed Apple's Core ML framework for integrating and deploying the machine learning model on mobile and wearable devices.

Python and Swift: For data preprocessing, model training, and app integration.

## Contributing

Pull requests are welcome. For major changes, please open an issue first
to discuss what you would like to change.

Please make sure to update tests as appropriate.


## License

[MIT](https://choosealicense.com/licenses/mit/)
